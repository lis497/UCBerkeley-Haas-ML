{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2cd168b-57f7-4901-a02b-60dbd53ed008",
   "metadata": {},
   "source": [
    "### Codio Activity 18.1: Tokenization\n",
    "\n",
    "This activity focuses on tokenizing text.  You will use `nltk` to tokenize words and sentences of given documents.  In general, tokenizing a text refers to the operation of splitting the text apart into chunks.  Here, our chunks can be individual \"words\" and \"sentences\".  These are not necessarily meant to refer to proper grammatical structure or meaning, however splitting entities based on white space, periods, or other punctuation.  \n",
    "\n",
    "#### Index\n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "- [Problem 4](#-Problem-4)\n",
    "- [Problem 5](#-Problem-5)\n",
    "- [Problem 6](#-Problem-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c0cb1f-2f49-4ac4-89b2-8c11dc290e31",
   "metadata": {},
   "source": [
    "#### The Data\n",
    "\n",
    "We use both a single piece of text in the form of a lead paragraph from Isaac Newton's *Principia* and a dataset including text data from [kaggle](https://www.kaggle.com/datasets/sankha1998/emotion?select=Emotion%28sad%29.csv) related to classifying WhatsApp status. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52f4d149-c455-4977-9c47-b1384a714661",
   "metadata": {},
   "outputs": [],
   "source": [
    "principia = '''\n",
    "Since the ancients (as we are told by Pappus), made great account of the science of mechanics in the investigation of natural things; and the moderns, laying aside substantial forms and occult qualities, have endeavoured to subject the phænomena of nature to the laws of mathematics, I have in this treatise cultivated mathematics so far as it regards philosophy. The ancients considered mechanics in a twofold respect; as rational, which proceeds accurately by demonstration: and practical. To practical mechanics all the manual arts belong, from which mechanics took its name. But as artificers do not work with perfect accuracy, it comes to pass that mechanics is so distinguished from geometry, that what is perfectly accurate is called geometrical, what is less so, is called mechanical. But the errors are not in the art, but in the artificers. He that works with less accuracy is an imperfect mechanic; and if any could work with perfect accuracy, he would be the most perfect mechanic of all; for the description if right lines and circles, upon which geometry is founded, belongs to mechanics. Geometry does not teach us to draw these lines, but requires them to be drawn; for it requires that the learner should first be taught to describe these accurately, before he enters upon geometry; then it shows how by these operations problems may be solved. To describe right lines and circles are problems, but not geometrical problems. The solution of these problems is required from mechanics; and by geometry the use of them, when so solved, is shown; and it is the glory of geometry that from those few principles, brought from without, it is able to produce so many things. Therefore geometry is founded in mechanical practice, and is nothing but that part of universal mechanics which accurately proposes and demonstrates the art of measuring. But since the manual arts are chiefly conversant in the moving of bodies, it comes to pass that geometry is commonly referred to their magnitudes, and mechanics to their motion. In this sense rational mechanics will be the science of motions resulting from any forces whatsoever, and of the forces required to produce any motions, accurately proposed and demonstrated. This part of mechanics was cultivated by the ancients in the five powers which relate to manual arts, who considered gravity (it not being a manual power), no otherwise than as it moved weights by those powers. Our design not respecting arts, but philosophy, and our subject not manual but natural powers, we consider chiefly those things which relate to gravity, levity, elastic force, the resistance of fluids, and the like forces, whether attractive or impulsive; and therefore we offer this work as the mathematical principles if philosophy; for all the difficulty of philosophy seems to consist in this—from the phænomena of motions to investigate the forces of nature, and then from these forces to demonstrate the other phænomena; and to this end the general propositions in the first and second book are directed. In the third book we give an example of this in the explication of the System of the World; for by the propositions mathematically demonstrated in the former books, we in the third derive from the celestial phenomena the forces of gravity with which bodies tend to the sun and the several planets. Then from these forces, by other propositions which are also mathematical, we deduce the motions of the planets, the comets, the moon, and the sea. I wish we could derive the rest of the phænomena of nature by the same kind of reasoning from mechanical principles; for I am induced by many reasons to suspect that they may all depend upon certain forces by which the particles of bodies, by some causes hitherto unknown, are either mutually impelled towards each other, and cohere in regular figures, or are repelled and recede from each other; which forces being unknown, philosophers have hitherto attempted the search of nature in vain; but I hope the principles here laid down will afford some light either to this or some truer method of philosophy.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73cb69dc-0eeb-4f28-b68e-e6e6997240b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Since the ancients (as we are told by Pappus), made great account of the science of mechanics in the investigation of natural things; and the moderns, laying aside substantial forms and occult qualities, have endeavoured to subject the phænomena of nature to the laws of mathematics, I have in this treatise cultivated mathematics so far as it regards philosophy. The ancients considered mechanics in a twofold respect; as rational, which proceeds accurately by demonstration: and practical. To practical mechanics all the manual arts belong, from which mechanics took its name. But as artificers do not work with perfect accuracy, it comes to pass that mechanics is so distinguished from geometry, that what is perfectly accurate is called geometrical, what is less so, is called mechanical. But the errors are not in the art, but in the artificers. He that works with less accuracy is an imperfect mechanic; and if any could work with perfect accuracy, he would be the most perfect mechanic of all; for the description if right lines and circles, upon which geometry is founded, belongs to mechanics. Geometry does not teach us to draw these lines, but requires them to be drawn; for it requires that the learner should first be taught to describe these accurately, before he enters upon geometry; then it shows how by these operations problems may be solved. To describe right lines and circles are problems, but not geometrical problems. The solution of these problems is required from mechanics; and by geometry the use of them, when so solved, is shown; and it is the glory of geometry that from those few principles, brought from without, it is able to produce so many things. Therefore geometry is founded in mechanical practice, and is nothing but that part of universal mechanics which accurately proposes and demonstrates the art of measuring. But since the manual arts are chiefly conversant in the moving of bodies, it comes to pass that geometry is commonly referred to their magnitudes, and mechanics to their motion. In this sense rational mechanics will be the science of motions resulting from any forces whatsoever, and of the forces required to produce any motions, accurately proposed and demonstrated. This part of mechanics was cultivated by the ancients in the five powers which relate to manual arts, who considered gravity (it not being a manual power), no otherwise than as it moved weights by those powers. Our design not respecting arts, but philosophy, and our subject not manual but natural powers, we consider chiefly those things which relate to gravity, levity, elastic force, the resistance of fluids, and the like forces, whether attractive or impulsive; and therefore we offer this work as the mathematical principles if philosophy; for all the difficulty of philosophy seems to consist in this—from the phænomena of motions to investigate the forces of nature, and then from these forces to demonstrate the other phænomena; and to this end the general propositions in the first and second book are directed. In the third book we give an example of this in the explication of the System of the World; for by the propositions mathematically demonstrated in the former books, we in the third derive from the celestial phenomena the forces of gravity with which bodies tend to the sun and the several planets. Then from these forces, by other propositions which are also mathematical, we deduce the motions of the planets, the comets, the moon, and the sea. I wish we could derive the rest of the phænomena of nature by the same kind of reasoning from mechanical principles; for I am induced by many reasons to suspect that they may all depend upon certain forces by which the particles of bodies, by some causes hitherto unknown, are either mutually impelled towards each other, and cohere in regular figures, or are repelled and recede from each other; which forces being unknown, philosophers have hitherto attempted the search of nature in vain; but I hope the principles here laid down will afford some light either to this or some truer method of philosophy.\n"
     ]
    }
   ],
   "source": [
    "print(principia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c0b6fe4-00ec-46b6-89ac-3f24fb8b24b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43914f1e-501b-4957-bc6d-4ff579dd3f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/kellen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize, sent_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bd011a-b273-4f46-9621-5560906efba1",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "#### Word Tokenizing a String\n",
    "\n",
    "Use the `word_tokenize` to split the string `principia` into individual elements of the text.  Assign your results as a list to `ans1` below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fec4db8-8e97-433e-ba63-54a7ee4ac676",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/Users/kellen/nltk_data'\n    - '/opt/miniconda3/envs/Linlin/nltk_data'\n    - '/opt/miniconda3/envs/Linlin/share/nltk_data'\n    - '/opt/miniconda3/envs/Linlin/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLookupError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m ans1 = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m ans1 = word_tokenize(principia)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(ans1))\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(ans1[:\u001b[32m5\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/Linlin/lib/python3.13/site-packages/nltk/tokenize/__init__.py:142\u001b[39m, in \u001b[36mword_tokenize\u001b[39m\u001b[34m(text, language, preserve_line)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mword_tokenize\u001b[39m(text, language=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m, preserve_line=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    128\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[33;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[32m    130\u001b[39m \u001b[33;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    140\u001b[39m \u001b[33;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     sentences = [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m    144\u001b[39m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer.tokenize(sent)\n\u001b[32m    145\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/Linlin/lib/python3.13/site-packages/nltk/tokenize/__init__.py:119\u001b[39m, in \u001b[36msent_tokenize\u001b[39m\u001b[34m(text, language)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msent_tokenize\u001b[39m(text, language=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    110\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    111\u001b[39m \u001b[33;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[32m    112\u001b[39m \u001b[33;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    117\u001b[39m \u001b[33;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     tokenizer = _get_punkt_tokenizer(language)\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer.tokenize(text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/Linlin/lib/python3.13/site-packages/nltk/tokenize/__init__.py:105\u001b[39m, in \u001b[36m_get_punkt_tokenizer\u001b[39m\u001b[34m(language)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;129m@functools\u001b[39m.lru_cache\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_punkt_tokenizer\u001b[39m(language=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     98\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[33;03m    A constructor for the PunktTokenizer that utilizes\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[33;03m    a lru cache for performance.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    103\u001b[39m \u001b[33;03m    :type language: str\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m PunktTokenizer(language)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/Linlin/lib/python3.13/site-packages/nltk/tokenize/punkt.py:1744\u001b[39m, in \u001b[36mPunktTokenizer.__init__\u001b[39m\u001b[34m(self, lang)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1743\u001b[39m     PunktSentenceTokenizer.\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1744\u001b[39m     \u001b[38;5;28mself\u001b[39m.load_lang(lang)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/Linlin/lib/python3.13/site-packages/nltk/tokenize/punkt.py:1749\u001b[39m, in \u001b[36mPunktTokenizer.load_lang\u001b[39m\u001b[34m(self, lang)\u001b[39m\n\u001b[32m   1746\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1747\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[32m-> \u001b[39m\u001b[32m1749\u001b[39m     lang_dir = find(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtokenizers/punkt_tab/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlang\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1750\u001b[39m     \u001b[38;5;28mself\u001b[39m._params = load_punkt_params(lang_dir)\n\u001b[32m   1751\u001b[39m     \u001b[38;5;28mself\u001b[39m._lang = lang\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/Linlin/lib/python3.13/site-packages/nltk/data.py:579\u001b[39m, in \u001b[36mfind\u001b[39m\u001b[34m(resource_name, paths)\u001b[39m\n\u001b[32m    577\u001b[39m sep = \u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m\n\u001b[32m    578\u001b[39m resource_not_found = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[31mLookupError\u001b[39m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/Users/kellen/nltk_data'\n    - '/opt/miniconda3/envs/Linlin/nltk_data'\n    - '/opt/miniconda3/envs/Linlin/share/nltk_data'\n    - '/opt/miniconda3/envs/Linlin/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "ans1 = ''\n",
    "ans1 = word_tokenize(principia)\n",
    "print(type(ans1))\n",
    "print(ans1[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8b03dc2-6694-4937-af96-2fd94e7b747f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/kellen/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b624d33-ecac-4be9-8834-f43e178aaf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['Since', 'the', 'ancients', '(', 'as']\n"
     ]
    }
   ],
   "source": [
    "ans1 = ''\n",
    "ans1 = word_tokenize(principia)\n",
    "print(type(ans1))\n",
    "print(ans1[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad474fae-6bed-4e3c-85d0-65d8a9ba51c3",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "#### Sentence Tokenization of a string\n",
    "\n",
    "Rather than breaking a text apart into individual tokens or \"words\" you can split based on sentences using `sent_tokenize`. Split the principia text into sentences and assign your answer as a list to `ans2` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fe7cfc1-81b3-45ac-896d-d360c4d9da12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans2 = sent_tokenize(principia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f015bee1-d15c-47c0-ac3b-f79312891364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['\\nSince the ancients (as we are told by Pappus), made great account of the science of mechanics in the investigation of natural things; and the moderns, laying aside substantial forms and occult qualities, have endeavoured to subject the phænomena of nature to the laws of mathematics, I have in this treatise cultivated mathematics so far as it regards philosophy.', 'The ancients considered mechanics in a twofold respect; as rational, which proceeds accurately by demonstration: and practical.']\n"
     ]
    }
   ],
   "source": [
    "print(type(ans2))\n",
    "print(ans2[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc70962-c57d-443b-8a0f-572ba5c524b5",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "\n",
    "#### Unique Words with `set`\n",
    "\n",
    "The tokenization does not yield unique words.  To create a collection of unique words, use the `set` function along with `word_tokenize` to create a mathematical set object of the words from the principia.  Assign your solution to `ans3` below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "865d9017-7df0-4022-859d-235cf7240900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'set'>\n",
      "{'endeavoured', 'those', 'science', 'occult', 'book', 'method', 'practice', 'respect', 'far', 'us', 'In', 'these', 'teach', ')', 'unknown', 'but', 'accurate', 'was', 'directed', 'requires', 'Geometry', 'attempted', 'mutually', 'motions', 'am', 'artificers', 'told', 'by', 'induced', 'figures', 'search', 'second', 'five', 'an', 'them', 'called', 'He', 'repelled', 'powers', 'part', 'resistance', 'most', 'mechanics', 'aside', 'qualities', 'art', 'consist', 'propositions', 'no', 'design', 'here', 'laying', 'elastic', 'truer', 'and', 'made', 'less', 'forces', 'whatsoever', 'work', 'vain', 'natural', 'geometry', 'great', 'taught', 'investigate', 'geometrical', 'description', 'to', 'regards', 'former', 'certain', 'depend', 'could', 'being', 'power', 'this', 'impulsive', 'since', 'lines', 'few', 'demonstrated', 'from', 'sea', 'several', 'ancients', 'for', 'chiefly', 'World', 'they', 'mathematics', 'will', 'our', 'in', 'impelled', 'solved', 'mathematical', 'consider', 'problems', 'phænomena', 'I', 'with', 'learner', 'bodies', ':', 'light', 'circles', 'celestial', 'accurately', 'laid', 'demonstrates', 'is', 'considered', 'shown', 'Then', 'causes', 'investigation', 'fluids', 'manual', 'then', 'required', 'produce', 'System', 'books', 'down', 'philosophy', 'any', 'nothing', 'otherwise', 'philosophers', 'Since', 'errors', 'or', ';', 'proceeds', 'proposes', 'force', 'its', 'levity', 'he', 'how', 'resulting', 'a', 'planets', 'subject', 'than', 'what', 'so', 'To', 'use', 'may', 'glory', 'nature', 'this—from', 'mathematically', 'have', 'The', 'reasons', 'cultivated', 'able', 'referred', 'if', 'substantial', 'But', 'other', 'perfectly', 'of', 'brought', '.', 'kind', 'perfect', 'shows', 'hope', 'demonstrate', 'Therefore', 'right', 'gravity', 'their', 'it', 'end', 'not', 'some', 'draw', 'whether', 'offer', 'therefore', 'pass', 'mechanic', '(', 'arts', 'particles', 'universal', 'that', 'name', 'magnitudes', 'drawn', 'sense', 'like', 'third', 'as', 'give', 'founded', 'suspect', 'belongs', 'enters', 'explication', 'practical', 'example', 'demonstration', 'recede', 'moved', 'attractive', 'derive', 'hitherto', 'cohere', 'regular', 'general', 'treatise', 'which', 'imperfect', 'all', 'solution', 'many', 'motion', 'also', 'twofold', 'This', 'rest', 'reasoning', 'account', 'respecting', 'moderns', 'relate', 'comes', 'moving', 'proposed', 'are', 'who', 'sun', 'should', 'accuracy', 'without', 'we', 'belong', 'measuring', 'afford', 'do', 'works', 'difficulty', 'before', 'towards', 'forms', 'the', 'moon', 'each', 'same', 'laws', 'mechanical', 'weights', 'first', 'does', 'when', ',', 'describe', 'deduce', 'principles', 'rational', 'took', 'seems', 'be', 'tend', 'phenomena', 'things', 'wish', 'commonly', 'upon', 'Pappus', 'operations', 'either', 'would', 'Our', 'distinguished', 'comets', 'conversant'}\n"
     ]
    }
   ],
   "source": [
    "ans3 = set(word_tokenize(principia))\n",
    "print(type(ans3))\n",
    "print(ans3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6893e246-6704-4bb2-b5ab-f950ed33bc23",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "\n",
    "#### Counts of words\n",
    "\n",
    "Determine the number of words in the principia text using `word_tokenize` and the `len` function.  Assign your answer as an integer to `ans4` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b4f864f-899d-4079-8875-128e1b61e2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "766"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans4 = len(word_tokenize(principia))\n",
    "ans4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9dda9f-a80a-4279-9f5c-eec4dff35d50",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "\n",
    "#### Lexical Diversity\n",
    "\n",
    "The lexical diversity of a text is the ratio of unique words to the total words.  Compute the lexical diversity of the principia text and assign your answer as a float to `ans5` below. \n",
    "\n",
    "Hint: Use the `length` function to find the numerial amount of unique and non-unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02c8db5d-cbe7-449d-b2b9-56d728df2c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans5_1 = len(set(word_tokenize(principia)))\n",
    "ans5_1\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6235fbbd-71c6-4415-9d76-77b9b4601921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "766"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans5_2 = len(word_tokenize(principia))\n",
    "ans5_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ab301d3-3249-4ad8-9b08-df1f22753fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.370757180156658"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans5 = ans5_1/ans5_2\n",
    "ans5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d256fee4-b529-493a-af5e-7da7709f11e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n",
      "0.370757180156658\n",
      "284\n",
      "766\n"
     ]
    }
   ],
   "source": [
    "print(type(ans5))\n",
    "print(ans5)\n",
    "print(ans5_1)\n",
    "print(ans5_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab303569-b790-4aae-a29c-4bb4d3405117",
   "metadata": {},
   "source": [
    "### Problem 6\n",
    "\n",
    "#### Text in a DataFrame\n",
    "\n",
    "To this point, we have been dealing with a block of text. How doe you work with multiple lines of text in a DataFrame? You can use `set` to determine the number of unique words (as above), but this will only provide a result PER ITEM, not for the entire DataFrame. To determine the total amount of words in a DataFrame, first use the `word_tokenize` function with the `.apply` method, and sum the resulting column to get a non-unique list of words.  Use your work above to determine the number of non-unique words (using `len`) from `happy_df` in the `content` feature given below.  Assign your answer as an integer to `ans6` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2d66a94-9e42-430c-aceb-e30eacfe254b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wants to know how the hell I can remember word...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love is a long sweet dream &amp; marriage is an al...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The world could be amazing when you are slight...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My secret talent is getting tired without doin...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Khatarnaak Whatsapp Status Ever… Can\\’t talk, ...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content sentiment\n",
       "0  Wants to know how the hell I can remember word...     happy\n",
       "1  Love is a long sweet dream & marriage is an al...     happy\n",
       "2  The world could be amazing when you are slight...     happy\n",
       "3  My secret talent is getting tired without doin...     happy\n",
       "4  Khatarnaak Whatsapp Status Ever… Can\\’t talk, ...     happy"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_df = pd.read_csv('codio_18_1_solution/data/Emotion(happy).csv')\n",
    "happy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68f825f3-410a-4bde-9e4c-d8841b718ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [Wants, to, know, how, the, hell, I, can, reme...\n",
       "1      [Love, is, a, long, sweet, dream, &, marriage,...\n",
       "2      [The, world, could, be, amazing, when, you, ar...\n",
       "3      [My, secret, talent, is, getting, tired, witho...\n",
       "4      [Khatarnaak, Whatsapp, Status, Ever…, Can\\, ’,...\n",
       "                             ...                        \n",
       "703    [If, I, know, what, love, is, ,, it, is, becau...\n",
       "704    [The, spaces, between, your, fingers, are, mea...\n",
       "705    [In, you, i, H, 've, Found, the, love, of, my,...\n",
       "706    [The, magic, of, first, love, is, our, ignoran...\n",
       "707    [Love, ca, n't, be, found, Where, it, does, n'...\n",
       "Name: content, Length: 708, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_df['content'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e749419-4969-4701-845d-7d6177bd3743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2095"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans6 = len(set(happy_df['content'].apply(word_tokenize).sum()))\n",
    "ans6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d785c4b6-aa84-4a32-ab54-f3bfb17871a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45befedf-9b54-4e70-b599-cafec2df9091",
   "metadata": {},
   "source": [
    "### Codio Activity 18.2: Named Entities\n",
    "\n",
    "This activity focuses on extracting named entities from text.  The named entities will be extracted using the `nltk` library.  You will read in the full text of Newton's *Principia* and identify the entities labeled as places.  \n",
    "\n",
    "#### Index\n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "- [Problem 4](#-Problem-4)\n",
    "- [Problem 5](#-Problem-5)\n",
    "- [Problem 6](#-Problem-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0add810b-5288-4793-b64e-ed775251abd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/kellen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/kellen/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/kellen/nltk_data...\n",
      "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data] Downloading package words to /Users/kellen/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kellen/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9d4df0-cd30-4b84-8fb4-3744ae0d4454",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "#### Opening a `.txt` file.\n",
    "\n",
    "Use the `open` function to open the text file with the Principia by Isaac Newton using the filepath given below.  Assign the text using the `readlines()` function to assign the text as a list of lines to the variable `principia` below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27ae0d07-23af-4d2e-8014-061f3d64e065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'codio_18_2_solution/data/Philosophiae_Naturalis_Principia_Mathematica.txt'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'codio_18_2_solution/data/Philosophiae_Naturalis_Principia_Mathematica.txt'\n",
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff5dba73-59f8-4233-a09c-1206adb37039",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filepath) as f:\n",
    "    principia = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55c5b561-7cdf-4211-9949-cbb92ce097ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(principia))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bec631b-583d-4c27-938c-8b6b45da4dd3",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "#### Tokenizing the text. \n",
    "\n",
    "Using the `principia` variable from problem 1, combine the `' '.join()` function with `word_tokenize` to create a list of tokens named `tokens` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04a072df-8937-4fcd-a622-e0f8ddfb647f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['Philosophiae', 'Naturalis', 'Principia', 'Mathematica', 'Isaacus']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(' '.join(principia))\n",
    "print(type(tokens))\n",
    "print(tokens[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe801d1-ceb5-494d-96ce-5dad19f1d9d0",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "\n",
    "#### Part of Speech Tags \n",
    "\n",
    "Use the `pos_tag` function to create the part of speech tagged corpus of the principia text.  Assign the tagged text to the variable `words_pos` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2fc564cb-43f5-4fec-bca4-addf482daf90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/kellen/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6af480be-ead6-442b-8180-d097a17a98f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[('Philosophiae', 'NNP'), ('Naturalis', 'NNP'), ('Principia', 'NNP'), ('Mathematica', 'NNP'), ('Isaacus', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "words_pos = nltk.pos_tag(tokens)\n",
    "\n",
    "print(type(words_pos))\n",
    "print(words_pos[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3195aed-c65b-4e4d-a0fe-3e1dc7e0b65e",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "\n",
    "#### Named Entities\n",
    "\n",
    "Use the tagged words in `words_pos` to create a list of tuples in the form (word, entity type) if the word has a named entity label.  Assign these tuples to the list `named_entities` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84ad9864-8ae3-4177-8027-6fd4b0084ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     /Users/kellen/nltk_data...\n",
      "[nltk_data]   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9171e8c-3ae7-4d40-97d4-40dcf2fb1245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[('Philosophiae', 'GSP'), ('Naturalis Principia Mathematica Isaacus Newtonus', 'PERSON'), ('Wikisource', 'GPE'), ('INDEX Tituli', 'ORGANIZATION'), ('Auctoris', 'GPE')]\n"
     ]
    }
   ],
   "source": [
    "named_entities = []\n",
    "for word in nltk.ne_chunk(words_pos):\n",
    "    if hasattr(word, 'label'):\n",
    "        named_entities.append((' '.join(c[0] for c in word.leaves()), word.label()))\n",
    "\n",
    "print(type(named_entities))\n",
    "print(named_entities[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0111f84f-7c39-4a58-9ee3-f39226fb0ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tree('GSP', [('Philosophiae', 'NNP')]),\n",
       " Tree('PERSON', [('Naturalis', 'NNP'), ('Principia', 'NNP'), ('Mathematica', 'NNP'), ('Isaacus', 'NNP'), ('Newtonus', 'NNP')]),\n",
       " ('1687', 'CD'),\n",
       " ('Exported', 'NNP'),\n",
       " ('from', 'IN'),\n",
       " Tree('GPE', [('Wikisource', 'NNP')]),\n",
       " ('on', 'IN'),\n",
       " ('April', 'NNP'),\n",
       " ('3', 'CD'),\n",
       " (',', ',')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = nltk.ne_chunk(words_pos)[0:10]\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cfe6ab08-866d-432f-aabf-38d203c48ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.tree.tree.Tree"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Tree in module nltk.tree.tree object:\n",
      "\n",
      "class Tree(builtins.list)\n",
      " |  Tree(node, children=None)\n",
      " |\n",
      " |  A Tree represents a hierarchical grouping of leaves and subtrees.\n",
      " |  For example, each constituent in a syntax tree is represented by a single Tree.\n",
      " |\n",
      " |  A tree's children are encoded as a list of leaves and subtrees,\n",
      " |  where a leaf is a basic (non-tree) value; and a subtree is a\n",
      " |  nested Tree.\n",
      " |\n",
      " |      >>> from nltk.tree import Tree\n",
      " |      >>> print(Tree(1, [2, Tree(3, [4]), 5]))\n",
      " |      (1 2 (3 4) 5)\n",
      " |      >>> vp = Tree('VP', [Tree('V', ['saw']),\n",
      " |      ...                  Tree('NP', ['him'])])\n",
      " |      >>> s = Tree('S', [Tree('NP', ['I']), vp])\n",
      " |      >>> print(s)\n",
      " |      (S (NP I) (VP (V saw) (NP him)))\n",
      " |      >>> print(s[1])\n",
      " |      (VP (V saw) (NP him))\n",
      " |      >>> print(s[1,1])\n",
      " |      (NP him)\n",
      " |      >>> t = Tree.fromstring(\"(S (NP I) (VP (V saw) (NP him)))\")\n",
      " |      >>> s == t\n",
      " |      True\n",
      " |      >>> t[1][1].set_label('X')\n",
      " |      >>> t[1][1].label()\n",
      " |      'X'\n",
      " |      >>> print(t)\n",
      " |      (S (NP I) (VP (V saw) (X him)))\n",
      " |      >>> t[0], t[1,1] = t[1,1], t[0]\n",
      " |      >>> print(t)\n",
      " |      (S (X him) (VP (V saw) (NP I)))\n",
      " |\n",
      " |  The length of a tree is the number of children it has.\n",
      " |\n",
      " |      >>> len(t)\n",
      " |      2\n",
      " |\n",
      " |  The set_label() and label() methods allow individual constituents\n",
      " |  to be labeled.  For example, syntax trees use this label to specify\n",
      " |  phrase tags, such as \"NP\" and \"VP\".\n",
      " |\n",
      " |  Several Tree methods use \"tree positions\" to specify\n",
      " |  children or descendants of a tree.  Tree positions are defined as\n",
      " |  follows:\n",
      " |\n",
      " |    - The tree position *i* specifies a Tree's *i*\\ th child.\n",
      " |    - The tree position ``()`` specifies the Tree itself.\n",
      " |    - If *p* is the tree position of descendant *d*, then\n",
      " |      *p+i* specifies the *i*\\ th child of *d*.\n",
      " |\n",
      " |  I.e., every tree position is either a single index *i*,\n",
      " |  specifying ``tree[i]``; or a sequence *i1, i2, ..., iN*,\n",
      " |  specifying ``tree[i1][i2]...[iN]``.\n",
      " |\n",
      " |  Construct a new tree.  This constructor can be called in one\n",
      " |  of two ways:\n",
      " |\n",
      " |  - ``Tree(label, children)`` constructs a new tree with the\n",
      " |      specified label and list of children.\n",
      " |\n",
      " |  - ``Tree.fromstring(s)`` constructs a new tree by parsing the string ``s``.\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      Tree\n",
      " |      builtins.list\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __add__(self, v)\n",
      " |      Return self+value.\n",
      " |\n",
      " |  __copy__(self)\n",
      " |\n",
      " |  __deepcopy__(self, memo)\n",
      " |\n",
      " |  __delitem__(self, index)\n",
      " |      Delete self[key].\n",
      " |\n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |\n",
      " |  __ge__ lambda self, other\n",
      " |\n",
      " |  __getitem__(self, index)\n",
      " |      Return self[index].\n",
      " |\n",
      " |  __gt__ lambda self, other\n",
      " |\n",
      " |  __init__(self, node, children=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  __le__ lambda self, other\n",
      " |\n",
      " |  __lt__(self, other)\n",
      " |      Return self<value.\n",
      " |\n",
      " |  __mul__(self, v)\n",
      " |      Return self*value.\n",
      " |\n",
      " |  __ne__ lambda self, other\n",
      " |      # @total_ordering doesn't work here, since the class inherits from a builtin class\n",
      " |\n",
      " |  __radd__(self, v)\n",
      " |\n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |\n",
      " |  __rmul__(self, v)\n",
      " |      Return value*self.\n",
      " |\n",
      " |  __setitem__(self, index, value)\n",
      " |      Set self[key] to value.\n",
      " |\n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |\n",
      " |  chomsky_normal_form(\n",
      " |      self,\n",
      " |      factor='right',\n",
      " |      horzMarkov=None,\n",
      " |      vertMarkov=0,\n",
      " |      childChar='|',\n",
      " |      parentChar='^'\n",
      " |  )\n",
      " |      This method can modify a tree in three ways:\n",
      " |\n",
      " |        1. Convert a tree into its Chomsky Normal Form (CNF)\n",
      " |           equivalent -- Every subtree has either two non-terminals\n",
      " |           or one terminal as its children.  This process requires\n",
      " |           the creation of more\"artificial\" non-terminal nodes.\n",
      " |        2. Markov (vertical) smoothing of children in new artificial\n",
      " |           nodes\n",
      " |        3. Horizontal (parent) annotation of nodes\n",
      " |\n",
      " |      :param factor: Right or left factoring method (default = \"right\")\n",
      " |      :type  factor: str = [left|right]\n",
      " |      :param horzMarkov: Markov order for sibling smoothing in artificial nodes (None (default) = include all siblings)\n",
      " |      :type  horzMarkov: int | None\n",
      " |      :param vertMarkov: Markov order for parent smoothing (0 (default) = no vertical annotation)\n",
      " |      :type  vertMarkov: int | None\n",
      " |      :param childChar: A string used in construction of the artificial nodes, separating the head of the\n",
      " |                        original subtree from the child nodes that have yet to be expanded (default = \"|\")\n",
      " |      :type  childChar: str\n",
      " |      :param parentChar: A string used to separate the node representation from its vertical annotation\n",
      " |      :type  parentChar: str\n",
      " |\n",
      " |  collapse_unary(self, collapsePOS=False, collapseRoot=False, joinChar='+')\n",
      " |      Collapse subtrees with a single child (ie. unary productions)\n",
      " |      into a new non-terminal (Tree node) joined by 'joinChar'.\n",
      " |      This is useful when working with algorithms that do not allow\n",
      " |      unary productions, and completely removing the unary productions\n",
      " |      would require loss of useful information.  The Tree is modified\n",
      " |      directly (since it is passed by reference) and no value is returned.\n",
      " |\n",
      " |      :param collapsePOS: 'False' (default) will not collapse the parent of leaf nodes (ie.\n",
      " |                          Part-of-Speech tags) since they are always unary productions\n",
      " |      :type  collapsePOS: bool\n",
      " |      :param collapseRoot: 'False' (default) will not modify the root production\n",
      " |                           if it is unary.  For the Penn WSJ treebank corpus, this corresponds\n",
      " |                           to the TOP -> productions.\n",
      " |      :type collapseRoot: bool\n",
      " |      :param joinChar: A string used to connect collapsed node values (default = \"+\")\n",
      " |      :type  joinChar: str\n",
      " |\n",
      " |  copy(self, deep=False)\n",
      " |      Return a shallow copy of the list.\n",
      " |\n",
      " |  draw(self)\n",
      " |      Open a new window containing a graphical diagram of this tree.\n",
      " |\n",
      " |  flatten(self)\n",
      " |      Return a flat version of the tree, with all non-root non-terminals removed.\n",
      " |\n",
      " |          >>> t = Tree.fromstring(\"(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))\")\n",
      " |          >>> print(t.flatten())\n",
      " |          (S the dog chased the cat)\n",
      " |\n",
      " |      :return: a tree consisting of this tree's root connected directly to\n",
      " |          its leaves, omitting all intervening non-terminal nodes.\n",
      " |      :rtype: Tree\n",
      " |\n",
      " |  freeze(self, leaf_freezer=None)\n",
      " |\n",
      " |  height(self)\n",
      " |      Return the height of the tree.\n",
      " |\n",
      " |          >>> t = Tree.fromstring(\"(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))\")\n",
      " |          >>> t.height()\n",
      " |          5\n",
      " |          >>> print(t[0,0])\n",
      " |          (D the)\n",
      " |          >>> t[0,0].height()\n",
      " |          2\n",
      " |\n",
      " |      :return: The height of this tree.  The height of a tree\n",
      " |          containing no children is 1; the height of a tree\n",
      " |          containing only leaves is 2; and the height of any other\n",
      " |          tree is one plus the maximum of its children's\n",
      " |          heights.\n",
      " |      :rtype: int\n",
      " |\n",
      " |  label(self)\n",
      " |      Return the node label of the tree.\n",
      " |\n",
      " |          >>> t = Tree.fromstring('(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))')\n",
      " |          >>> t.label()\n",
      " |          'S'\n",
      " |\n",
      " |      :return: the node label (typically a string)\n",
      " |      :rtype: any\n",
      " |\n",
      " |  leaf_treeposition(self, index)\n",
      " |      :return: The tree position of the ``index``-th leaf in this\n",
      " |          tree.  I.e., if ``tp=self.leaf_treeposition(i)``, then\n",
      " |          ``self[tp]==self.leaves()[i]``.\n",
      " |\n",
      " |      :raise IndexError: If this tree contains fewer than ``index+1``\n",
      " |          leaves, or if ``index<0``.\n",
      " |\n",
      " |  leaves(self)\n",
      " |      Return the leaves of the tree.\n",
      " |\n",
      " |          >>> t = Tree.fromstring(\"(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))\")\n",
      " |          >>> t.leaves()\n",
      " |          ['the', 'dog', 'chased', 'the', 'cat']\n",
      " |\n",
      " |      :return: a list containing this tree's leaves.\n",
      " |          The order reflects the order of the\n",
      " |          leaves in the tree's hierarchical structure.\n",
      " |      :rtype: list\n",
      " |\n",
      " |  pformat(self, margin=70, indent=0, nodesep='', parens='()', quotes=False)\n",
      " |      :return: A pretty-printed string representation of this tree.\n",
      " |      :rtype: str\n",
      " |      :param margin: The right margin at which to do line-wrapping.\n",
      " |      :type margin: int\n",
      " |      :param indent: The indentation level at which printing\n",
      " |          begins.  This number is used to decide how far to indent\n",
      " |          subsequent lines.\n",
      " |      :type indent: int\n",
      " |      :param nodesep: A string that is used to separate the node\n",
      " |          from the children.  E.g., the default value ``':'`` gives\n",
      " |          trees like ``(S: (NP: I) (VP: (V: saw) (NP: it)))``.\n",
      " |\n",
      " |  pformat_latex_qtree(self)\n",
      " |      Returns a representation of the tree compatible with the\n",
      " |      LaTeX qtree package. This consists of the string ``\\Tree``\n",
      " |      followed by the tree represented in bracketed notation.\n",
      " |\n",
      " |      For example, the following result was generated from a parse tree of\n",
      " |      the sentence ``The announcement astounded us``::\n",
      " |\n",
      " |        \\Tree [.I'' [.N'' [.D The ] [.N' [.N announcement ] ] ]\n",
      " |            [.I' [.V'' [.V' [.V astounded ] [.N'' [.N' [.N us ] ] ] ] ] ] ]\n",
      " |\n",
      " |      See https://www.ling.upenn.edu/advice/latex.html for the LaTeX\n",
      " |      style file for the qtree package.\n",
      " |\n",
      " |      :return: A latex qtree representation of this tree.\n",
      " |      :rtype: str\n",
      " |\n",
      " |  pos(self)\n",
      " |      Return a sequence of pos-tagged words extracted from the tree.\n",
      " |\n",
      " |          >>> t = Tree.fromstring(\"(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))\")\n",
      " |          >>> t.pos()\n",
      " |          [('the', 'D'), ('dog', 'N'), ('chased', 'V'), ('the', 'D'), ('cat', 'N')]\n",
      " |\n",
      " |      :return: a list of tuples containing leaves and pre-terminals (part-of-speech tags).\n",
      " |          The order reflects the order of the leaves in the tree's hierarchical structure.\n",
      " |      :rtype: list(tuple)\n",
      " |\n",
      " |  pprint(self, **kwargs)\n",
      " |      Print a string representation of this Tree to 'stream'\n",
      " |\n",
      " |  pretty_print(self, sentence=None, highlight=(), stream=None, **kwargs)\n",
      " |      Pretty-print this tree as ASCII or Unicode art.\n",
      " |      For explanation of the arguments, see the documentation for\n",
      " |      `nltk.tree.prettyprinter.TreePrettyPrinter`.\n",
      " |\n",
      " |  productions(self)\n",
      " |      Generate the productions that correspond to the non-terminal nodes of the tree.\n",
      " |      For each subtree of the form (P: C1 C2 ... Cn) this produces a production of the\n",
      " |      form P -> C1 C2 ... Cn.\n",
      " |\n",
      " |          >>> t = Tree.fromstring(\"(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))\")\n",
      " |          >>> t.productions() # doctest: +NORMALIZE_WHITESPACE\n",
      " |          [S -> NP VP, NP -> D N, D -> 'the', N -> 'dog', VP -> V NP, V -> 'chased',\n",
      " |          NP -> D N, D -> 'the', N -> 'cat']\n",
      " |\n",
      " |      :rtype: list(Production)\n",
      " |\n",
      " |  set_label(self, label)\n",
      " |      Set the node label of the tree.\n",
      " |\n",
      " |          >>> t = Tree.fromstring(\"(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))\")\n",
      " |          >>> t.set_label(\"T\")\n",
      " |          >>> print(t)\n",
      " |          (T (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))\n",
      " |\n",
      " |      :param label: the node label (typically a string)\n",
      " |      :type label: any\n",
      " |\n",
      " |  subtrees(self, filter=None)\n",
      " |      Generate all the subtrees of this tree, optionally restricted\n",
      " |      to trees matching the filter function.\n",
      " |\n",
      " |          >>> t = Tree.fromstring(\"(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))\")\n",
      " |          >>> for s in t.subtrees(lambda t: t.height() == 2):\n",
      " |          ...     print(s)\n",
      " |          (D the)\n",
      " |          (N dog)\n",
      " |          (V chased)\n",
      " |          (D the)\n",
      " |          (N cat)\n",
      " |\n",
      " |      :type filter: function\n",
      " |      :param filter: the function to filter all local trees\n",
      " |\n",
      " |  treeposition_spanning_leaves(self, start, end)\n",
      " |      :return: The tree position of the lowest descendant of this\n",
      " |          tree that dominates ``self.leaves()[start:end]``.\n",
      " |      :raise ValueError: if ``end <= start``\n",
      " |\n",
      " |  treepositions(self, order='preorder')\n",
      " |          >>> t = Tree.fromstring(\"(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))\")\n",
      " |          >>> t.treepositions() # doctest: +ELLIPSIS\n",
      " |          [(), (0,), (0, 0), (0, 0, 0), (0, 1), (0, 1, 0), (1,), (1, 0), (1, 0, 0), ...]\n",
      " |          >>> for pos in t.treepositions('leaves'):\n",
      " |          ...     t[pos] = t[pos][::-1].upper()\n",
      " |          >>> print(t)\n",
      " |          (S (NP (D EHT) (N GOD)) (VP (V DESAHC) (NP (D EHT) (N TAC))))\n",
      " |\n",
      " |      :param order: One of: ``preorder``, ``postorder``, ``bothorder``,\n",
      " |          ``leaves``.\n",
      " |\n",
      " |  un_chomsky_normal_form(\n",
      " |      self,\n",
      " |      expandUnary=True,\n",
      " |      childChar='|',\n",
      " |      parentChar='^',\n",
      " |      unaryChar='+'\n",
      " |  )\n",
      " |      This method modifies the tree in three ways:\n",
      " |\n",
      " |        1. Transforms a tree in Chomsky Normal Form back to its\n",
      " |           original structure (branching greater than two)\n",
      " |        2. Removes any parent annotation (if it exists)\n",
      " |        3. (optional) expands unary subtrees (if previously\n",
      " |           collapsed with collapseUnary(...) )\n",
      " |\n",
      " |      :param expandUnary: Flag to expand unary or not (default = True)\n",
      " |      :type  expandUnary: bool\n",
      " |      :param childChar: A string separating the head node from its children in an artificial node (default = \"|\")\n",
      " |      :type  childChar: str\n",
      " |      :param parentChar: A string separating the node label from its parent annotation (default = \"^\")\n",
      " |      :type  parentChar: str\n",
      " |      :param unaryChar: A string joining two non-terminals in a unary production (default = \"+\")\n",
      " |      :type  unaryChar: str\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |\n",
      " |  convert(tree)\n",
      " |      Convert a tree between different subtypes of Tree.  ``cls`` determines\n",
      " |      which class will be used to encode the new tree.\n",
      " |\n",
      " |      :type tree: Tree\n",
      " |      :param tree: The tree that should be converted.\n",
      " |      :return: The new Tree.\n",
      " |\n",
      " |  fromlist(l)\n",
      " |      :type l: list\n",
      " |      :param l: a tree represented as nested lists\n",
      " |\n",
      " |      :return: A tree corresponding to the list representation ``l``.\n",
      " |      :rtype: Tree\n",
      " |\n",
      " |      Convert nested lists to a NLTK Tree\n",
      " |\n",
      " |  fromstring(\n",
      " |      s,\n",
      " |      brackets='()',\n",
      " |      read_node=None,\n",
      " |      read_leaf=None,\n",
      " |      node_pattern=None,\n",
      " |      leaf_pattern=None,\n",
      " |      remove_empty_top_bracketing=False\n",
      " |  )\n",
      " |      Read a bracketed tree string and return the resulting tree.\n",
      " |      Trees are represented as nested brackettings, such as::\n",
      " |\n",
      " |        (S (NP (NNP John)) (VP (V runs)))\n",
      " |\n",
      " |      :type s: str\n",
      " |      :param s: The string to read\n",
      " |\n",
      " |      :type brackets: str (length=2)\n",
      " |      :param brackets: The bracket characters used to mark the\n",
      " |          beginning and end of trees and subtrees.\n",
      " |\n",
      " |      :type read_node: function\n",
      " |      :type read_leaf: function\n",
      " |      :param read_node, read_leaf: If specified, these functions\n",
      " |          are applied to the substrings of ``s`` corresponding to\n",
      " |          nodes and leaves (respectively) to obtain the values for\n",
      " |          those nodes and leaves.  They should have the following\n",
      " |          signature:\n",
      " |\n",
      " |             read_node(str) -> value\n",
      " |\n",
      " |          For example, these functions could be used to process nodes\n",
      " |          and leaves whose values should be some type other than\n",
      " |          string (such as ``FeatStruct``).\n",
      " |          Note that by default, node strings and leaf strings are\n",
      " |          delimited by whitespace and brackets; to override this\n",
      " |          default, use the ``node_pattern`` and ``leaf_pattern``\n",
      " |          arguments.\n",
      " |\n",
      " |      :type node_pattern: str\n",
      " |      :type leaf_pattern: str\n",
      " |      :param node_pattern, leaf_pattern: Regular expression patterns\n",
      " |          used to find node and leaf substrings in ``s``.  By\n",
      " |          default, both nodes patterns are defined to match any\n",
      " |          sequence of non-whitespace non-bracket characters.\n",
      " |\n",
      " |      :type remove_empty_top_bracketing: bool\n",
      " |      :param remove_empty_top_bracketing: If the resulting tree has\n",
      " |          an empty node label, and is length one, then return its\n",
      " |          single child instead.  This is useful for treebank trees,\n",
      " |          which sometimes contain an extra level of bracketing.\n",
      " |\n",
      " |      :return: A tree corresponding to the string representation ``s``.\n",
      " |          If this class method is called using a subclass of Tree,\n",
      " |          then it will return a tree of that type.\n",
      " |      :rtype: Tree\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  node\n",
      " |      Outdated method to access the node value; use the label() method instead.\n",
      " |\n",
      " |      @deprecated: Use label() instead\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __hash__ = None\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from builtins.list:\n",
      " |\n",
      " |  __contains__(self, key, /)\n",
      " |      Return bool(key in self).\n",
      " |\n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |\n",
      " |  __iadd__(self, value, /)\n",
      " |      Implement self+=value.\n",
      " |\n",
      " |  __imul__(self, value, /)\n",
      " |      Implement self*=value.\n",
      " |\n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |\n",
      " |  __len__(self, /)\n",
      " |      Return len(self).\n",
      " |\n",
      " |  __reversed__(self, /)\n",
      " |      Return a reverse iterator over the list.\n",
      " |\n",
      " |  __sizeof__(self, /)\n",
      " |      Return the size of the list in memory, in bytes.\n",
      " |\n",
      " |  append(self, object, /)\n",
      " |      Append object to the end of the list.\n",
      " |\n",
      " |  clear(self, /)\n",
      " |      Remove all items from list.\n",
      " |\n",
      " |  count(self, value, /)\n",
      " |      Return number of occurrences of value.\n",
      " |\n",
      " |  extend(self, iterable, /)\n",
      " |      Extend list by appending elements from the iterable.\n",
      " |\n",
      " |  index(self, value, start=0, stop=9223372036854775807, /)\n",
      " |      Return first index of value.\n",
      " |\n",
      " |      Raises ValueError if the value is not present.\n",
      " |\n",
      " |  insert(self, index, object, /)\n",
      " |      Insert object before index.\n",
      " |\n",
      " |  pop(self, index=-1, /)\n",
      " |      Remove and return item at index (default last).\n",
      " |\n",
      " |      Raises IndexError if list is empty or index is out of range.\n",
      " |\n",
      " |  remove(self, value, /)\n",
      " |      Remove first occurrence of value.\n",
      " |\n",
      " |      Raises ValueError if the value is not present.\n",
      " |\n",
      " |  reverse(self, /)\n",
      " |      Reverse *IN PLACE*.\n",
      " |\n",
      " |  sort(self, /, *, key=None, reverse=False)\n",
      " |      Sort the list in ascending order and return None.\n",
      " |\n",
      " |      The sort is in-place (i.e. the list itself is modified) and stable (i.e. the\n",
      " |      order of two equal elements is maintained).\n",
      " |\n",
      " |      If a key function is given, apply it once to each list item and sort them,\n",
      " |      ascending or descending, according to their function values.\n",
      " |\n",
      " |      The reverse flag can be set to sort in descending order.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from builtins.list:\n",
      " |\n",
      " |  __class_getitem__(object, /)\n",
      " |      See PEP 585\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from builtins.list:\n",
      " |\n",
      " |  __new__(*args, **kwargs) class method of builtins.list\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display(type(temp[0]))\n",
    "display(type(temp[2]))\n",
    "help(temp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3af4c03f-f008-4663-8268-ca8126af4e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_frozen_class',\n",
       " '_get_node',\n",
       " '_label',\n",
       " '_parse_error',\n",
       " '_pformat_flat',\n",
       " '_repr_svg_',\n",
       " '_set_node',\n",
       " 'append',\n",
       " 'chomsky_normal_form',\n",
       " 'clear',\n",
       " 'collapse_unary',\n",
       " 'convert',\n",
       " 'copy',\n",
       " 'count',\n",
       " 'draw',\n",
       " 'extend',\n",
       " 'flatten',\n",
       " 'freeze',\n",
       " 'fromlist',\n",
       " 'fromstring',\n",
       " 'height',\n",
       " 'index',\n",
       " 'insert',\n",
       " 'label',\n",
       " 'leaf_treeposition',\n",
       " 'leaves',\n",
       " 'node',\n",
       " 'pformat',\n",
       " 'pformat_latex_qtree',\n",
       " 'pop',\n",
       " 'pos',\n",
       " 'pprint',\n",
       " 'pretty_print',\n",
       " 'productions',\n",
       " 'remove',\n",
       " 'reverse',\n",
       " 'set_label',\n",
       " 'sort',\n",
       " 'subtrees',\n",
       " 'treeposition_spanning_leaves',\n",
       " 'treepositions',\n",
       " 'un_chomsky_normal_form']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: \"__\" not in x, dir(temp[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "85a1328a-5dcb-4057-b37e-6265918aad8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GSP Philosophiae/NNP)\n",
      "[('Philosophiae', 'NNP')]\n",
      "GSP\n",
      "----------------\n",
      "(PERSON\n",
      "  Naturalis/NNP\n",
      "  Principia/NNP\n",
      "  Mathematica/NNP\n",
      "  Isaacus/NNP\n",
      "  Newtonus/NNP)\n",
      "[('Naturalis', 'NNP'), ('Principia', 'NNP'), ('Mathematica', 'NNP'), ('Isaacus', 'NNP'), ('Newtonus', 'NNP')]\n",
      "PERSON\n",
      "----------------\n",
      "(GPE Wikisource/NNP)\n",
      "[('Wikisource', 'NNP')]\n",
      "GPE\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "for i in temp:\n",
    "    if hasattr(i, \"label\"):\n",
    "        print(i)\n",
    "        print(i.leaves())\n",
    "        print(i.label())\n",
    "        print(\"----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f0ee83-20cd-4864-b81e-e69d4fb43bef",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "\n",
    "#### Removing People\n",
    "\n",
    "Use the `named_entities` list to include only entities labeled `GPE` and create a list of these words lowercased as `places` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0940943-8cb1-4cad-bffc-98ea2958623b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wikisource', 'auctoris', 'umbilico', 'orbibus', 'orbibus']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "places = [i[0].lower() for i in named_entities if i[1] == 'GPE']\n",
    "places[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a60d0e-7e67-46a3-bdec-4880f072518b",
   "metadata": {},
   "source": [
    "### Problem 6\n",
    "\n",
    "#### Removing stopwords\n",
    "\n",
    "Use the list `places` to remove all stopwords.  Assign these words as a list to `no_stops` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54e18fa2-19b1-40f9-92fb-12cab63e43fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5d07d09-6578-4b4b-92e7-445208ea84ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['wikisource', 'auctoris', 'umbilico', 'orbibus', 'orbibus', 'superficiebus', 'mediis', 'fluida']\n"
     ]
    }
   ],
   "source": [
    "no_stops = [i for i in places if not i in stopwords.words('English')]\n",
    "print(type(no_stops))\n",
    "print(no_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb0ec9a-96b9-48ea-81a3-1685c327e11c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4864add1-5a36-4327-954e-4c8041b899e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
