{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ed55b5d",
   "metadata": {},
   "source": [
    "### Codio Activity 23.4: Fine Tuning a Pre-trained Network\n",
    "\n",
    "In addition to the use of a pre-trained network to extract features from a different dataset, the weights can be adjusted or **fine-tuned** as a last step to squeeze additional performance from the network.  To do so, you will again use the `EfficientNetV2B0` network on the `cifar10` data from `keras`.  This time you are encouraged to use the functional API syntax to construct your network.  \n",
    "\n",
    "For a second example, consult the `keras` documentation example [here](https://keras.io/guides/transfer_learning/). \n",
    "\n",
    "#### Index\n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "\n",
    "Run the code cell below to import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f50dfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tensor/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2B0\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import Model, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2a96fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "sub_indices = pd.DataFrame(y_train, columns= [\"labels\"]).groupby('labels', group_keys=False).apply(lambda x: x.sample(frac=0.3, random_state=123)).index\n",
    "X_train = X_train[sub_indices]\n",
    "y_train = y_train[sub_indices]\n",
    "\n",
    "Y_train = to_categorical(y_train)\n",
    "Y_test = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5a51c0",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "#### Training the Network to Convergence\n",
    "\n",
    "In the code cell below, use the function `EfficientNetV2B0` with the appropriate input shape and the argument `include_top` equal to `False` to create the model you will be using for this activity. Assign your result to `base_model`.\n",
    "\n",
    "Use the function `Input()` with argument `shape` equal to `(32, 32, 3)` and assign your result to the variable `inputs`.\n",
    "\n",
    "Use `base_model` with argument equal to `inputs` and assign your result to the variable `x`.\n",
    "\n",
    "Use the function `Flatten` to flatten `x`. The pseudocode to complete this step is given below:\n",
    "\n",
    "```Python\n",
    "x = Flatten()(...)\n",
    "```\n",
    "\n",
    "Pass `x` through a `Dense` layer with 10 hidden nodes and `activation` equal to `relu` and assign the result to the variable `output`. The pseudocode to complete this step is given below:\n",
    "\n",
    "```Python\n",
    "output = Dense(..., activation = ...)(...)\n",
    "```\n",
    "\n",
    "Use the code `base_model.trainable = False` to ensure that your weights are not trainable.\n",
    "\n",
    "Use the function `Model()` with argument `inputs` and `output` to define your model. Assign the result to the variable `model`.\n",
    "\n",
    "Compile `model` using `categorical_crossentropy` as your `loss` and `accuracy` as your `metric`.\n",
    "\n",
    "Use the `fit()` function on `model` to fit the  training data `X_train` and `Y_train`. Set the argument `validation_data` equal to `(X_test, Y_test)` and the argument `epochs` equal to 1.  Assign the result to the variable `bottom_model` below. \n",
    "\n",
    "NOTE: This question is computationally expensive, so please be patient with the processing. It may take a few minutes based on your computing power. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f71288f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-05 18:42:55.420910: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 15s 28ms/step - loss: 1.8889 - accuracy: 0.3452 - val_loss: 1.5742 - val_accuracy: 0.4703\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " efficientnetv2-b0 (Function  (None, 1, 1, 1280)       5919312   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                12810     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,932,232\n",
      "Trainable params: 12,920\n",
      "Non-trainable params: 5,919,312\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "base_model = ''\n",
    "inputs = ''\n",
    "x = ''\n",
    "x = ''\n",
    "x = ''\n",
    "output = ''\n",
    "model = ''\n",
    "bottom_model = ''\n",
    "\n",
    "base_model = EfficientNetV2B0(input_shape = (32,32,3), include_top = False)\n",
    "inputs = Input(shape = (32,32,3))\n",
    "x = base_model(inputs)\n",
    "x = Flatten()(x)\n",
    "x = Dense(10, activation = 'relu')(x)\n",
    "output = Dense(10, activation = 'sigmoid')(x)\n",
    "base_model.trainable = False\n",
    "model = Model(inputs, output)\n",
    "model.compile(loss = 'categorical_crossentropy',  metrics = ['accuracy'])\n",
    "bottom_model = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), \n",
    "                    epochs = 1)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "126e44f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 15s 28ms/step - loss: 2.0068 - accuracy: 0.3001 - val_loss: 1.7090 - val_accuracy: 0.4111\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " efficientnetv2-b0 (Function  (None, 1, 1, 1280)       5919312   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1280)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                12810     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,932,232\n",
      "Trainable params: 12,920\n",
      "Non-trainable params: 5,919,312\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "base_model = ''\n",
    "inputs = ''\n",
    "x = ''\n",
    "x = ''\n",
    "x = ''\n",
    "output = ''\n",
    "model = ''\n",
    "#be sure to compile\n",
    "\n",
    "bottom_model = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "base_model = EfficientNetV2B0(input_shape = (32, 32, 3), include_top=False)\n",
    "inputs = Input(shape = (32, 32, 3))\n",
    "x = base_model(inputs)\n",
    "x = Flatten()(x)\n",
    "x = Dense(10, activation = 'relu')(x)\n",
    "output = Dense(10, activation = 'sigmoid')(x)\n",
    "base_model.trainable = False\n",
    "model = Model(inputs, output)\n",
    "model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "bottom_model = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), \n",
    "                    epochs = 1)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20639026",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "#### Setting to Trainable\n",
    "\n",
    "In the code cell below, use the code `base_model.trainable = True` to ensure that your weights are now trainable.\n",
    "\n",
    "\n",
    "Set the final five layers to trainable in the `base_model` as demonstrated in the lectures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1a38d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.trainable #are the base model weights set to trainable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83b73aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer is trainable: False\n",
      "Layer is trainable: False\n",
      "Layer is trainable: False\n",
      "Layer is trainable: False\n",
      "Layer is trainable: False\n",
      "Layer is trainable: True\n",
      "Layer is trainable: True\n",
      "Layer is trainable: True\n",
      "Layer is trainable: True\n",
      "Layer is trainable: True\n"
     ]
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-5]:\n",
    "    layer.trainable = False\n",
    "for i, layer in enumerate(base_model.layers[-10:]):\n",
    "    print(f'Layer is trainable: {layer.trainable}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04b3189",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "\n",
    "#### Refitting the network\n",
    "\n",
    "In the code cell below, use the function `compile` on `model` using `categorical_crossentropy` as your `loss` and `accuracy` as your `metric`.\n",
    "\n",
    "Next, use the `fit()` function on `model` to fit the  training data `X_train` and `Y_train`. Set the argument `validation_data` equal to `(X_test, Y_test)` and the argument `epochs` equal to 1.  Assign the result to the variable `fine_tuned_history` below. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce8cd7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 16s 29ms/step - loss: 1.5699 - accuracy: 0.4723 - val_loss: 1.2277 - val_accuracy: 0.5907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47226667404174805"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "fine_tuned_history = model.fit(X_train, Y_train, validation_data = (X_test, Y_test), epochs = 1)\n",
    "\n",
    "fine_tuned_history.history['accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c50e5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
